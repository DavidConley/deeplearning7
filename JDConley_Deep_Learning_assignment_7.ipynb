{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#John David Conley\n",
        "#Deep Learning ICP 7\n",
        "from google.colab import drive \n",
        "drive.mount('/content/gdrive') "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Yt4az3JpgWd",
        "outputId": "c3a2740d-6d2c-4dc6-c22b-f2cd5bc195df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lesson Overview:\n",
        "\n",
        "In this lesson, we are going to discuss Image classification with CNN.\n",
        "\n",
        "Use Case Description:\n",
        "\n",
        "Image Classification with CNN\n",
        "1. Training the model\n",
        "2. Evaluating the model\n",
        "\n",
        "Programming elements:\n",
        "1. About CNN\n",
        "2. Hyperparameters of CNN\n",
        "3. Image classification with CNN\n",
        "\n",
        "In class programming:\n",
        "1. Follow the instruction below and then report how the performance changed.(apply all at once)\n",
        "\n",
        "• Convolutional input layer, 32 feature maps with a size of 3×3 and a rectifier activation function.\n",
        "\n",
        "• Dropout layer at 20%.\n",
        "\n",
        "• Convolutional layer, 32 feature maps with a size of 3×3 and a rectifier activation function.\n",
        "\n",
        "• Max Pool layer with size 2×2.\n",
        "\n",
        "• Convolutional layer, 64 feature maps with a size of 3×3 and a rectifier activation function.\n",
        "\n",
        "• Dropout layer at 20%.\n",
        "\n",
        "• Convolutional layer, 64 feature maps with a size of 3×3 and a rectifier activation function.\n",
        "\n",
        "• Max Pool layer with size 2×2.\n",
        "\n",
        "• Convolutional layer, 128 feature maps with a size of 3×3 and a rectifier activation function.\n",
        "\n",
        "• Dropout layer at 20%.\n",
        "\n",
        "• Convolutional layer,128 feature maps with a size of 3×3 and a rectifier activation function.\n",
        "\n",
        "• Max Pool layer with size 2×2.\n",
        "\n",
        "• Flatten layer.\n",
        "\n",
        "• Dropout layer at 20%.\n",
        "\n",
        "• Fully connected layer with 1024 units and a rectifier activation function.\n",
        "\n",
        "• Dropout layer at 20%.\n",
        "\n",
        "• Fully connected layer with 512 units and a rectifier activation function.\n",
        "\n",
        "• Dropout layer at 20%.\n",
        "\n",
        "• Fully connected output layer with 10 units and a Softmax activation function\n",
        "\n",
        "Did the performance change?\n",
        "\n",
        "2. Predict the first 4 images of the test data using the above model. Then, compare with the actual label for those 4 \n",
        "images to check whether or not the model has predicted correctly.\n",
        "\n",
        "3. Visualize Loss and Accuracy using the history object"
      ],
      "metadata": {
        "id": "5Cor1iwunu6I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Original\n",
        "# Simple CNN model for CIFAR-10\n",
        "import numpy\n",
        "from keras.datasets import cifar10\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import Flatten\n",
        "from keras.constraints import maxnorm\n",
        "from keras.optimizers import SGD\n",
        "from keras.layers.convolutional import Conv2D\n",
        "from keras.layers.convolutional import MaxPooling2D\n",
        "from keras.utils import np_utils\n",
        "#from keras import backend as K\n",
        "#K.set_image_dim_ordering('th')\n",
        "\n",
        "# fix random seed for reproducibility\n",
        "seed = 7\n",
        "numpy.random.seed(seed)\n",
        "# load data\n",
        "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
        "# normalize inputs from 0-255 to 0.0-1.0\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train = X_train / 255.0\n",
        "X_test = X_test / 255.0\n",
        "# one hot encode outputs\n",
        "y_train = np_utils.to_categorical(y_train)\n",
        "y_test = np_utils.to_categorical(y_test)\n",
        "num_classes = y_test.shape[1]\n",
        "# Create the model\n",
        "model = Sequential()\n",
        "#Convolutional input layer, 32 feature maps with a size of 3×3 and a rectifier activation function. Dropout layer at 20%.\n",
        "model.add(Conv2D(32, (3, 3), input_shape=(32, 32, 3), padding='same', activation='relu', kernel_constraint=maxnorm(3)))\n",
        "model.add(Dropout(0.2))\n",
        "#Convolutional layer, 32 feature maps with a size of 3×3 and a rectifier activation function. Max Pool layer with size 2×2.\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', padding='same', kernel_constraint=maxnorm(3)))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "#Convolutional layer, 64 feature maps with a size of 3×3 and a rectifier activation function. Dropout layer at 20%.\n",
        "\n",
        "#Convolutional layer, 64 feature maps with a size of 3×3 and a rectifier activation function. Max Pool layer with size 2×2.\n",
        "\n",
        "#Convolutional layer, 128 feature maps with a size of 3×3 and a rectifier activation function. Dropout layer at 20%.\n",
        "\n",
        "#Convolutional layer, 128 feature maps with a size of 3×3 and a rectifier activation function. Max Pool layer with size 2×2.\n",
        "\n",
        "#Flatten layer.\n",
        "model.add(Flatten())\n",
        "#Dropout layer at 20%. Fully connected layer with 1024 units and a rectifier activation function.\n",
        "\n",
        "#Dropout layer at 20%. Fully connected layer with 512 units and a rectifier activation function.\n",
        "model.add(Dense(512, activation='relu', kernel_constraint=maxnorm(3)))\n",
        "model.add(Dropout(0.5))\n",
        "#Dropout layer at 20%. Fully connected output layer with 10 units and a Softmax activation function\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "# Compile model\n",
        "epochs = 25\n",
        "lrate = 0.01\n",
        "decay = lrate/epochs\n",
        "sgd = SGD(lr=lrate, momentum=0.9, decay=decay, nesterov=False)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
        "print(model.summary())\n",
        "# Fit the model\n",
        "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=epochs, batch_size=32)\n",
        "# Final evaluation of the model\n",
        "scores = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"Accuracy: %.2f%%\" % (scores[1]*100))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c14Ga_WfnsVB",
        "outputId": "404a12a9-ec39-4d38-b6e9-d5e53220981f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_4 (Conv2D)           (None, 32, 32, 32)        896       \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 32, 32, 32)        0         \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 32, 32, 32)        9248      \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 16, 16, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 8192)              0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 512)               4194816   \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 10)                5130      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,210,090\n",
            "Trainable params: 4,210,090\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/25\n",
            "1563/1563 [==============================] - 273s 174ms/step - loss: 1.6586 - accuracy: 0.4013 - val_loss: 1.3110 - val_accuracy: 0.5295\n",
            "Epoch 2/25\n",
            "1563/1563 [==============================] - 286s 183ms/step - loss: 1.2818 - accuracy: 0.5423 - val_loss: 1.1351 - val_accuracy: 0.5972\n",
            "Epoch 3/25\n",
            "1563/1563 [==============================] - 269s 172ms/step - loss: 1.1155 - accuracy: 0.6002 - val_loss: 1.0617 - val_accuracy: 0.6207\n",
            "Epoch 4/25\n",
            "1563/1563 [==============================] - 262s 168ms/step - loss: 0.9957 - accuracy: 0.6469 - val_loss: 1.0129 - val_accuracy: 0.6442\n",
            "Epoch 5/25\n",
            "1563/1563 [==============================] - 269s 172ms/step - loss: 0.8941 - accuracy: 0.6822 - val_loss: 0.9524 - val_accuracy: 0.6598\n",
            "Epoch 6/25\n",
            "1563/1563 [==============================] - 273s 174ms/step - loss: 0.8057 - accuracy: 0.7141 - val_loss: 0.9363 - val_accuracy: 0.6728\n",
            "Epoch 7/25\n",
            "1563/1563 [==============================] - 273s 175ms/step - loss: 0.7300 - accuracy: 0.7420 - val_loss: 0.9410 - val_accuracy: 0.6746\n",
            "Epoch 8/25\n",
            "1563/1563 [==============================] - 267s 171ms/step - loss: 0.6694 - accuracy: 0.7633 - val_loss: 0.9106 - val_accuracy: 0.6852\n",
            "Epoch 9/25\n",
            "1563/1563 [==============================] - 262s 168ms/step - loss: 0.6135 - accuracy: 0.7820 - val_loss: 0.9138 - val_accuracy: 0.6867\n",
            "Epoch 10/25\n",
            "1563/1563 [==============================] - 262s 168ms/step - loss: 0.5525 - accuracy: 0.8053 - val_loss: 0.9326 - val_accuracy: 0.6913\n",
            "Epoch 11/25\n",
            "1563/1563 [==============================] - 262s 168ms/step - loss: 0.5063 - accuracy: 0.8184 - val_loss: 0.9343 - val_accuracy: 0.6953\n",
            "Epoch 12/25\n",
            "1563/1563 [==============================] - 262s 168ms/step - loss: 0.4690 - accuracy: 0.8320 - val_loss: 0.9406 - val_accuracy: 0.6945\n",
            "Epoch 13/25\n",
            "1563/1563 [==============================] - 265s 170ms/step - loss: 0.4298 - accuracy: 0.8507 - val_loss: 0.9438 - val_accuracy: 0.7012\n",
            "Epoch 14/25\n",
            "1563/1563 [==============================] - 262s 167ms/step - loss: 0.3910 - accuracy: 0.8634 - val_loss: 0.9817 - val_accuracy: 0.6952\n",
            "Epoch 15/25\n",
            "1563/1563 [==============================] - 261s 167ms/step - loss: 0.3597 - accuracy: 0.8723 - val_loss: 1.0040 - val_accuracy: 0.6994\n",
            "Epoch 16/25\n",
            "1563/1563 [==============================] - 262s 168ms/step - loss: 0.3388 - accuracy: 0.8802 - val_loss: 0.9935 - val_accuracy: 0.7002\n",
            "Epoch 17/25\n",
            "1563/1563 [==============================] - 263s 168ms/step - loss: 0.3162 - accuracy: 0.8885 - val_loss: 1.0009 - val_accuracy: 0.7009\n",
            "Epoch 18/25\n",
            "1563/1563 [==============================] - 263s 168ms/step - loss: 0.2933 - accuracy: 0.8968 - val_loss: 1.0413 - val_accuracy: 0.7017\n",
            "Epoch 19/25\n",
            "1563/1563 [==============================] - 261s 167ms/step - loss: 0.2777 - accuracy: 0.9028 - val_loss: 1.0161 - val_accuracy: 0.7036\n",
            "Epoch 20/25\n",
            "1563/1563 [==============================] - 263s 168ms/step - loss: 0.2590 - accuracy: 0.9096 - val_loss: 1.0316 - val_accuracy: 0.7030\n",
            "Epoch 21/25\n",
            "1563/1563 [==============================] - 261s 167ms/step - loss: 0.2424 - accuracy: 0.9151 - val_loss: 1.0562 - val_accuracy: 0.7035\n",
            "Epoch 22/25\n",
            "1563/1563 [==============================] - 262s 168ms/step - loss: 0.2307 - accuracy: 0.9193 - val_loss: 1.0647 - val_accuracy: 0.7062\n",
            "Epoch 23/25\n",
            "1563/1563 [==============================] - 262s 168ms/step - loss: 0.2153 - accuracy: 0.9259 - val_loss: 1.1045 - val_accuracy: 0.7052\n",
            "Epoch 24/25\n",
            "1563/1563 [==============================] - 267s 171ms/step - loss: 0.2090 - accuracy: 0.9271 - val_loss: 1.1126 - val_accuracy: 0.7066\n",
            "Epoch 25/25\n",
            "1563/1563 [==============================] - 259s 166ms/step - loss: 0.2018 - accuracy: 0.9309 - val_loss: 1.1148 - val_accuracy: 0.7047\n",
            "Accuracy: 70.47%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Altered\n",
        "# Simple CNN model for CIFAR-10\n",
        "import numpy\n",
        "from keras.datasets import cifar10\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import Flatten\n",
        "from keras.constraints import maxnorm\n",
        "from keras.optimizers import SGD\n",
        "from keras.layers.convolutional import Conv2D\n",
        "from keras.layers.convolutional import MaxPooling2D\n",
        "from keras.utils import np_utils\n",
        "#from keras import backend as K\n",
        "#K.set_image_dim_ordering('th')\n",
        "\n",
        "# fix random seed for reproducibility\n",
        "seed = 7\n",
        "numpy.random.seed(seed)\n",
        "# load data\n",
        "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
        "# normalize inputs from 0-255 to 0.0-1.0\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train = X_train / 255.0\n",
        "X_test = X_test / 255.0\n",
        "# one hot encode outputs\n",
        "y_train = np_utils.to_categorical(y_train)\n",
        "y_test = np_utils.to_categorical(y_test)\n",
        "num_classes = y_test.shape[1]\n",
        "# Create the model\n",
        "model = Sequential()\n",
        "#Convolutional input layer, 32 feature maps with a size of 3×3 and a rectifier activation function. Dropout layer at 20%.\n",
        "model.add(Conv2D(32, (3, 3), input_shape=(32, 32, 3), padding='same', activation='relu', kernel_constraint=maxnorm(3)))\n",
        "model.add(Dropout(0.2))\n",
        "#Convolutional layer, 32 feature maps with a size of 3×3 and a rectifier activation function. Max Pool layer with size 2×2.\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', padding='same', kernel_constraint=maxnorm(3)))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "#Convolutional layer, 64 feature maps with a size of 3×3 and a rectifier activation function. Dropout layer at 20%.\n",
        "model.add(Conv2D(64, (3, 3), activation='relu', padding='same', kernel_constraint=maxnorm(3)))\n",
        "model.add(Dropout(0.2))\n",
        "#Convolutional layer, 64 feature maps with a size of 3×3 and a rectifier activation function. Max Pool layer with size 2×2.\n",
        "model.add(Conv2D(64, (3, 3), activation='relu', padding='same', kernel_constraint=maxnorm(3)))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "#Convolutional layer, 128 feature maps with a size of 3×3 and a rectifier activation function. Dropout layer at 20%.\n",
        "model.add(Conv2D(128, (3, 3), activation='relu', padding='same', kernel_constraint=maxnorm(3)))\n",
        "model.add(Dropout(0.2))\n",
        "#Convolutional layer, 128 feature maps with a size of 3×3 and a rectifier activation function. Max Pool layer with size 2×2.\n",
        "model.add(Conv2D(128, (3, 3), activation='relu', padding='same', kernel_constraint=maxnorm(3)))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "#Flatten layer.\n",
        "model.add(Flatten())\n",
        "#Dropout layer at 20%. Fully connected layer with 1024 units and a rectifier activation function.\n",
        "model.add(Dense(1024, activation='relu', kernel_constraint=maxnorm(3)))\n",
        "model.add(Dropout(0.2))\n",
        "#Dropout layer at 20%. Fully connected layer with 512 units and a rectifier activation function.\n",
        "model.add(Dense(512, activation='relu', kernel_constraint=maxnorm(3)))\n",
        "model.add(Dropout(0.2))\n",
        "#Dropout layer at 20%. Fully connected output layer with 10 units and a Softmax activation function\n",
        "model.add(Dense(10, activation='softmax', kernel_constraint=maxnorm(3)))\n",
        "model.add(Dropout(0.2))\n",
        "#model.add(Dense(num_classes, activation='softmax'))\n",
        "# Compile model\n",
        "epochs = 25\n",
        "lrate = 0.01\n",
        "decay = lrate/epochs\n",
        "sgd = SGD(lr=lrate, momentum=0.9, decay=decay, nesterov=False)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
        "print(model.summary())\n",
        "# Fit the model\n",
        "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=epochs, batch_size=32)\n",
        "# Final evaluation of the model\n",
        "scores = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"Accuracy: %.2f%%\" % (scores[1]*100))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GZUfn8qntJVK",
        "outputId": "e49620aa-41c3-48cd-990b-1d72685a9814"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_12 (Conv2D)          (None, 32, 32, 32)        896       \n",
            "                                                                 \n",
            " dropout_12 (Dropout)        (None, 32, 32, 32)        0         \n",
            "                                                                 \n",
            " conv2d_13 (Conv2D)          (None, 32, 32, 32)        9248      \n",
            "                                                                 \n",
            " max_pooling2d_6 (MaxPooling  (None, 16, 16, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_14 (Conv2D)          (None, 16, 16, 64)        18496     \n",
            "                                                                 \n",
            " dropout_13 (Dropout)        (None, 16, 16, 64)        0         \n",
            "                                                                 \n",
            " conv2d_15 (Conv2D)          (None, 16, 16, 64)        36928     \n",
            "                                                                 \n",
            " max_pooling2d_7 (MaxPooling  (None, 8, 8, 64)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_16 (Conv2D)          (None, 8, 8, 128)         73856     \n",
            "                                                                 \n",
            " dropout_14 (Dropout)        (None, 8, 8, 128)         0         \n",
            "                                                                 \n",
            " conv2d_17 (Conv2D)          (None, 8, 8, 128)         147584    \n",
            "                                                                 \n",
            " max_pooling2d_8 (MaxPooling  (None, 4, 4, 128)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 2048)              0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 1024)              2098176   \n",
            "                                                                 \n",
            " dropout_15 (Dropout)        (None, 1024)              0         \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 512)               524800    \n",
            "                                                                 \n",
            " dropout_16 (Dropout)        (None, 512)               0         \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 10)                5130      \n",
            "                                                                 \n",
            " dropout_17 (Dropout)        (None, 10)                0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,915,114\n",
            "Trainable params: 2,915,114\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/25\n",
            "1563/1563 [==============================] - 489s 312ms/step - loss: 4.5414 - accuracy: 0.2843 - val_loss: 1.7405 - val_accuracy: 0.3887\n",
            "Epoch 2/25\n",
            "1563/1563 [==============================] - 481s 308ms/step - loss: 4.2714 - accuracy: 0.4084 - val_loss: 1.3690 - val_accuracy: 0.4934\n",
            "Epoch 3/25\n",
            "1563/1563 [==============================] - 476s 305ms/step - loss: 4.1294 - accuracy: 0.4614 - val_loss: 1.2372 - val_accuracy: 0.5472\n",
            "Epoch 4/25\n",
            "1563/1563 [==============================] - 481s 308ms/step - loss: 4.0451 - accuracy: 0.5001 - val_loss: 1.1375 - val_accuracy: 0.5856\n",
            "Epoch 5/25\n",
            "1563/1563 [==============================] - 475s 304ms/step - loss: 3.9384 - accuracy: 0.5305 - val_loss: 1.0849 - val_accuracy: 0.6125\n",
            "Epoch 6/25\n",
            "1563/1563 [==============================] - 470s 301ms/step - loss: 3.8757 - accuracy: 0.5540 - val_loss: 0.9678 - val_accuracy: 0.6482\n",
            "Epoch 7/25\n",
            "1563/1563 [==============================] - 467s 299ms/step - loss: 3.8740 - accuracy: 0.5741 - val_loss: 0.9578 - val_accuracy: 0.6588\n",
            "Epoch 8/25\n",
            "1563/1563 [==============================] - 467s 299ms/step - loss: 3.8204 - accuracy: 0.5915 - val_loss: 0.8500 - val_accuracy: 0.7002\n",
            "Epoch 9/25\n",
            "1563/1563 [==============================] - 463s 296ms/step - loss: 3.7909 - accuracy: 0.6044 - val_loss: 0.8281 - val_accuracy: 0.7047\n",
            "Epoch 10/25\n",
            "1563/1563 [==============================] - 456s 292ms/step - loss: 3.7613 - accuracy: 0.6180 - val_loss: 0.8133 - val_accuracy: 0.7101\n",
            "Epoch 11/25\n",
            "1563/1563 [==============================] - 458s 293ms/step - loss: 3.7011 - accuracy: 0.6309 - val_loss: 0.8049 - val_accuracy: 0.7190\n",
            "Epoch 12/25\n",
            "1563/1563 [==============================] - 456s 292ms/step - loss: 3.6729 - accuracy: 0.6396 - val_loss: 0.7623 - val_accuracy: 0.7355\n",
            "Epoch 13/25\n",
            "1563/1563 [==============================] - 465s 297ms/step - loss: 3.6159 - accuracy: 0.6495 - val_loss: 0.7715 - val_accuracy: 0.7327\n",
            "Epoch 14/25\n",
            "1563/1563 [==============================] - 468s 299ms/step - loss: 3.5962 - accuracy: 0.6597 - val_loss: 0.7557 - val_accuracy: 0.7412\n",
            "Epoch 15/25\n",
            "1563/1563 [==============================] - 468s 299ms/step - loss: 3.6294 - accuracy: 0.6660 - val_loss: 0.7758 - val_accuracy: 0.7383\n",
            "Epoch 16/25\n",
            "1563/1563 [==============================] - 470s 301ms/step - loss: 3.5690 - accuracy: 0.6748 - val_loss: 0.7576 - val_accuracy: 0.7473\n",
            "Epoch 17/25\n",
            "1563/1563 [==============================] - 464s 297ms/step - loss: 3.5387 - accuracy: 0.6798 - val_loss: 0.7299 - val_accuracy: 0.7526\n",
            "Epoch 18/25\n",
            "1563/1563 [==============================] - 470s 301ms/step - loss: 3.5234 - accuracy: 0.6866 - val_loss: 0.7430 - val_accuracy: 0.7513\n",
            "Epoch 19/25\n",
            "1563/1563 [==============================] - 464s 297ms/step - loss: 3.5089 - accuracy: 0.6942 - val_loss: 0.7565 - val_accuracy: 0.7523\n",
            "Epoch 20/25\n",
            "1563/1563 [==============================] - 460s 294ms/step - loss: 3.4685 - accuracy: 0.6984 - val_loss: 0.7513 - val_accuracy: 0.7545\n",
            "Epoch 21/25\n",
            "1563/1563 [==============================] - 460s 294ms/step - loss: 3.5159 - accuracy: 0.7026 - val_loss: 0.7350 - val_accuracy: 0.7571\n",
            "Epoch 22/25\n",
            "1563/1563 [==============================] - 463s 297ms/step - loss: 3.5280 - accuracy: 0.7044 - val_loss: 0.7478 - val_accuracy: 0.7623\n",
            "Epoch 23/25\n",
            "1563/1563 [==============================] - 461s 295ms/step - loss: 3.4632 - accuracy: 0.7135 - val_loss: 0.7648 - val_accuracy: 0.7644\n",
            "Epoch 24/25\n",
            "1563/1563 [==============================] - 462s 295ms/step - loss: 3.4182 - accuracy: 0.7198 - val_loss: 0.7772 - val_accuracy: 0.7616\n",
            "Epoch 25/25\n",
            "1563/1563 [==============================] - 460s 294ms/step - loss: nan - accuracy: 0.7204 - val_loss: 0.7961 - val_accuracy: 0.7591\n",
            "Accuracy: 75.91%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Accuracy is slightly better. Processing time is much worse."
      ],
      "metadata": {
        "id": "auMZLRMK8Pzp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#2\n",
        "from keras.models import load_model\n",
        "import cv2\n",
        "import numpy as np\n",
        "from keras import backend as K\n",
        "K.image_data_format()\n",
        "K.set_image_data_format('channels_first')\n",
        "from keras.preprocessing import image\n",
        "from keras.utils import img_to_array\n",
        "model = Sequential()\n",
        "\n",
        "seed = 7\n",
        "numpy.random.seed(seed)\n",
        "# load data\n",
        "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
        "# normalize inputs from 0-255 to 0.0-1.0\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train = X_train / 255.0\n",
        "X_test = X_test / 255.0\n",
        "# one hot encode outputs\n",
        "y_train = np_utils.to_categorical(y_train)\n",
        "y_test = np_utils.to_categorical(y_test)\n",
        "num_classes = y_test.shape[1]\n",
        "# Create the model\n",
        "model = Sequential()\n",
        "#Convolutional input layer, 32 feature maps with a size of 3×3 and a rectifier activation function. Dropout layer at 20%.\n",
        "model.add(Conv2D(32, (3, 3), input_shape=(32, 32, 3), padding='same', activation='relu', kernel_constraint=maxnorm(3)))\n",
        "model.add(Dropout(0.2))\n",
        "#Convolutional layer, 32 feature maps with a size of 3×3 and a rectifier activation function. Max Pool layer with size 2×2.\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', padding='same', kernel_constraint=maxnorm(3)))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "#Convolutional layer, 64 feature maps with a size of 3×3 and a rectifier activation function. Dropout layer at 20%.\n",
        "model.add(Conv2D(64, (3, 3), activation='relu', padding='same', kernel_constraint=maxnorm(3)))\n",
        "model.add(Dropout(0.2))\n",
        "#Convolutional layer, 64 feature maps with a size of 3×3 and a rectifier activation function. Max Pool layer with size 2×2.\n",
        "model.add(Conv2D(64, (3, 3), activation='relu', padding='same', kernel_constraint=maxnorm(3)))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "#Convolutional layer, 128 feature maps with a size of 3×3 and a rectifier activation function. Dropout layer at 20%.\n",
        "model.add(Conv2D(128, (3, 3), activation='relu', padding='same', kernel_constraint=maxnorm(3)))\n",
        "model.add(Dropout(0.2))\n",
        "#Convolutional layer, 128 feature maps with a size of 3×3 and a rectifier activation function. Max Pool layer with size 2×2.\n",
        "model.add(Conv2D(128, (3, 3), activation='relu', padding='same', kernel_constraint=maxnorm(3)))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "#Flatten layer.\n",
        "model.add(Flatten())\n",
        "#Dropout layer at 20%. Fully connected layer with 1024 units and a rectifier activation function.\n",
        "model.add(Dense(1024, activation='relu', kernel_constraint=maxnorm(3)))\n",
        "model.add(Dropout(0.2))\n",
        "#Dropout layer at 20%. Fully connected layer with 512 units and a rectifier activation function.\n",
        "model.add(Dense(512, activation='relu', kernel_constraint=maxnorm(3)))\n",
        "model.add(Dropout(0.2))\n",
        "#Dropout layer at 20%. Fully connected output layer with 10 units and a Softmax activation function\n",
        "model.add(Dense(10, activation='softmax', kernel_constraint=maxnorm(3)))\n",
        "model.add(Dropout(0.2))\n",
        "model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
        "\n",
        "# predicting images\n",
        "img1 = cifar10.load_data()[0]\n",
        "x1 = image.img_to_array(img1)\n",
        "x1 = np.expand_dims(x1, axis=0)\n",
        "\n",
        "images = np.vstack([x1])\n",
        "classes = model.predict(images, batch_size=10)\n",
        "print(classes)\n",
        "\n",
        "img2 = cifar10.load_data()[1]\n",
        "x2 = image.img_to_array(img2)\n",
        "x2 = np.expand_dims(x2, axis=0)\n",
        "\n",
        "images = np.vstack([x2])\n",
        "classes = model.predict(images, batch_size=10)\n",
        "print(classes)\n",
        "\n",
        "img3 = cifar10.load_data()[2]\n",
        "x3 = image.img_to_array(img3)\n",
        "x3 = np.expand_dims(x3, axis=0)\n",
        "\n",
        "images = np.vstack([x3])\n",
        "classes = model.predict(images, batch_size=10)\n",
        "print(classes)\n",
        "\n",
        "img4 = cifar10.load_data()[3]\n",
        "x4 = image.img_to_array(img4)\n",
        "x4 = np.expand_dims(x4, axis=0)\n",
        "\n",
        "images = np.vstack([x4])\n",
        "classes = model.predict(images, batch_size=10)\n",
        "print(classes)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 484
        },
        "id": "ro-z9fMo8XbT",
        "outputId": "cc4071df-5731-4466-eaf2-47950f53b8ca"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-9dc04de7d329>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;31m#Convolutional layer, 64 feature maps with a size of 3×3 and a rectifier activation function. Max Pool layer with size 2×2.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mConv2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'same'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_constraint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmaxnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMaxPooling2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpool_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;31m#Convolutional layer, 128 feature maps with a size of 3×3 and a rectifier activation function. Dropout layer at 20%.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mConv2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'same'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_constraint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmaxnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/trackable/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    203\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs, op_def, extract_traceback)\u001b[0m\n\u001b[1;32m   1965\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1966\u001b[0m     \u001b[0;31m# Convert to ValueError for backwards compatibility.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1967\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1968\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1969\u001b[0m   \u001b[0;31m# Record the current Python stack trace as the creating stacktrace of this\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Exception encountered when calling layer \"max_pooling2d_18\" (type MaxPooling2D).\n\nNegative dimension size caused by subtracting 2 from 1 for '{{node max_pooling2d_18/MaxPool}} = MaxPool[T=DT_FLOAT, data_format=\"NCHW\", explicit_paddings=[], ksize=[1, 1, 2, 2], padding=\"VALID\", strides=[1, 1, 2, 2]](Placeholder)' with input shapes: [?,64,16,1].\n\nCall arguments received by layer \"max_pooling2d_18\" (type MaxPooling2D):\n  • inputs=tf.Tensor(shape=(None, 64, 16, 1), dtype=float32)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#3\n",
        "from keras.models import load_model\n",
        "import cv2\n",
        "import numpy as np\n",
        "from keras import backend as K\n",
        "K.image_data_format()\n",
        "K.set_image_data_format('channels_first')\n",
        "from keras.preprocessing import image\n",
        "from keras.utils import img_to_array\n",
        "model = Sequential()\n",
        "\n",
        "seed = 7\n",
        "numpy.random.seed(seed)\n",
        "# load data\n",
        "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
        "# normalize inputs from 0-255 to 0.0-1.0\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train = X_train / 255.0\n",
        "X_test = X_test / 255.0\n",
        "# one hot encode outputs\n",
        "y_train = np_utils.to_categorical(y_train)\n",
        "y_test = np_utils.to_categorical(y_test)\n",
        "num_classes = y_test.shape[1]\n",
        "# Create the model\n",
        "model = Sequential()\n",
        "#Convolutional input layer, 32 feature maps with a size of 3×3 and a rectifier activation function. Dropout layer at 20%.\n",
        "model.add(Conv2D(32, (3, 3), input_shape=(32, 32, 3), padding='same', activation='relu', kernel_constraint=maxnorm(3)))\n",
        "model.add(Dropout(0.2))\n",
        "#Convolutional layer, 32 feature maps with a size of 3×3 and a rectifier activation function. Max Pool layer with size 2×2.\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', padding='same', kernel_constraint=maxnorm(3)))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "#Convolutional layer, 64 feature maps with a size of 3×3 and a rectifier activation function. Dropout layer at 20%.\n",
        "model.add(Conv2D(64, (3, 3), activation='relu', padding='same', kernel_constraint=maxnorm(3)))\n",
        "model.add(Dropout(0.2))\n",
        "#Convolutional layer, 64 feature maps with a size of 3×3 and a rectifier activation function. Max Pool layer with size 2×2.\n",
        "model.add(Conv2D(64, (3, 3), activation='relu', padding='same', kernel_constraint=maxnorm(3)))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "#Convolutional layer, 128 feature maps with a size of 3×3 and a rectifier activation function. Dropout layer at 20%.\n",
        "model.add(Conv2D(128, (3, 3), activation='relu', padding='same', kernel_constraint=maxnorm(3)))\n",
        "model.add(Dropout(0.2))\n",
        "#Convolutional layer, 128 feature maps with a size of 3×3 and a rectifier activation function. Max Pool layer with size 2×2.\n",
        "model.add(Conv2D(128, (3, 3), activation='relu', padding='same', kernel_constraint=maxnorm(3)))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "#Flatten layer.\n",
        "model.add(Flatten())\n",
        "#Dropout layer at 20%. Fully connected layer with 1024 units and a rectifier activation function.\n",
        "model.add(Dense(1024, activation='relu', kernel_constraint=maxnorm(3)))\n",
        "model.add(Dropout(0.2))\n",
        "#Dropout layer at 20%. Fully connected layer with 512 units and a rectifier activation function.\n",
        "model.add(Dense(512, activation='relu', kernel_constraint=maxnorm(3)))\n",
        "model.add(Dropout(0.2))\n",
        "#Dropout layer at 20%. Fully connected output layer with 10 units and a Softmax activation function\n",
        "model.add(Dense(10, activation='softmax', kernel_constraint=maxnorm(3)))\n",
        "model.add(Dropout(0.2))\n",
        "model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
        "history = model.fit(X_train, y_train, validation_split=0.20, epochs=25, batch_size=32, verbose=0)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 484
        },
        "id": "kANoWuF0FVmF",
        "outputId": "d4fc0424-3473-4271-de60-7a336c91d765"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-a54f6c07c2c2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;31m#Convolutional layer, 64 feature maps with a size of 3×3 and a rectifier activation function. Max Pool layer with size 2×2.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mConv2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'same'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_constraint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmaxnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMaxPooling2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpool_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;31m#Convolutional layer, 128 feature maps with a size of 3×3 and a rectifier activation function. Dropout layer at 20%.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mConv2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'same'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_constraint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmaxnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/trackable/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    203\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs, op_def, extract_traceback)\u001b[0m\n\u001b[1;32m   1965\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1966\u001b[0m     \u001b[0;31m# Convert to ValueError for backwards compatibility.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1967\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1968\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1969\u001b[0m   \u001b[0;31m# Record the current Python stack trace as the creating stacktrace of this\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Exception encountered when calling layer \"max_pooling2d_16\" (type MaxPooling2D).\n\nNegative dimension size caused by subtracting 2 from 1 for '{{node max_pooling2d_16/MaxPool}} = MaxPool[T=DT_FLOAT, data_format=\"NCHW\", explicit_paddings=[], ksize=[1, 1, 2, 2], padding=\"VALID\", strides=[1, 1, 2, 2]](Placeholder)' with input shapes: [?,64,16,1].\n\nCall arguments received by layer \"max_pooling2d_16\" (type MaxPooling2D):\n  • inputs=tf.Tensor(shape=(None, 64, 16, 1), dtype=float32)"
          ]
        }
      ]
    }
  ]
}